# 14.10.24 - 20.10.24: GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models

**Paper**: [https://arxiv.org/pdf/2410.05229v1](https://arxiv.org/pdf/2410.05229v1)

## Introduction

This paper claims to provide experimental evidence to the hypothesis that LLMs do not do real reasoning, but instead do complex pattern matching.
Especially on Twitter this new publication (re-)ignited the discussion over this question in the last couple of days.
On the one side you had many people who saw their view, that LLMs do not really reason, confirmed.
On the other hand many people also saw issues with the provided evidence in the paper and questioned if humans themselves even
qualify under the papers concept of reasoning. There was even a comedic paper parodying this [https://pdfupload.io/docs/e5595fd9](https://pdfupload.io/docs/e5595fd9).

The authors main innovation is an extension of the mathematical reasoning benchmark GSM8K. They introduce a more general version they call
GSM-Symbolic, for which key aspects of the questions (like numerical values and names) vary.

## GSM-Symbolic

GSM8K contains grade school level text questions. I will provide the same example they use in the paper

"When *Sophie* watches her *nephew*, she gets out a variety of toys for him.
The bag of building blocks has *31* blocks in it. The bin of stuffed
animals has *8* stuffed animals inside. The tower of stacking rings has *9*
multicolored rings on it. *Sophie* recently bought a tube of bouncy
balls, bringing her total number of toys for her *nephew* up to *62*. How
many bouncy balls came in the tube?"


